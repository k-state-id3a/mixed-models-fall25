---
title: 'Day 3: GLMMs'
author: "Claudio D. Silva Jr"
output: html_document
---

# Day 3: Generalized Linear Mixed Models - GLMMs

Learning objectives:

-   What are GLMMs

-   What is a distributional assumption

-   How to fit a GLMM

$$
\\[0.2in]
$$

## What are GLMMs

-   Generalized Linear Models are models in which we can assume different distributions for our data beyond the Normal distribution.

-   Similar to general linear models, GLMs can also have random effects, thus, Generalized Linear Mixed Models - GLMMs.

$$
\\[0.2in]
$$

### The structure of a GLMMs

Remember that for a **LMMs**, assuming $\mathbf{y}$ arises from a normal distribution, we have:

$$
\mathbf{y = X\beta + Zu + \epsilon} \\ \mathbf{\begin{bmatrix} u \\ \epsilon \end{bmatrix} \sim \begin{pmatrix}  \begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} G \; 0 \\ 0 \; R \end{bmatrix} \end{pmatrix}}
$$

In which:

-   $\mathbf{X\beta}$ represents our fixed effects, where $\mathbf{X}$ is a matrix containing our explanatory variables and $\mathbf{\beta}$ a vector containing the fixed-effects parameters.

-   $\mathbf{Zu}$ represents our random effects, where $\mathbf{Z}$ is a design matrix and $\mathbf{u}$ is the vector containing the random effects parameters.

-   $\mathbf{\epsilon}$ is the vector containing the residuals.

-   From $\mathbf{Zu + \epsilon}$ we have: $\mathbf{G}$ is the variance-covariance matrix of the random effects, and $\mathbf{R}$ is the variance-covariance matrix of the residuals.

    -   $\mathbf{G = \sigma^2_uI}$ and $\mathbf{R = \sigma^2I}$, in which $\mathbf{I}$ is the identity matrix.

Which is similar to:

$$
\mathbf{u} \sim N(0, I\sigma^2_u) \\
\mathbf{\epsilon} \sim N(0, I\sigma^2)
$$

In this case:

$$
E(\mathbf{y}) = \mathbf{X\beta}, \\
Var(\mathbf{y}) = \mathbf{ZGZ' + R}
$$

We can also write this model as:

$$
\mathbf{y} \sim N(\mathbf{X\beta}, \; \mathbf{ZGZ' + R})
$$

or:

$$
\mathbf{y} \sim N(\mathbf{X\beta}, \; \mathbf{\Sigma}) \\
\mathbf{\Sigma} = \mathbf{ZGZ' + R}
$$

For **GLMMs** the structure changes based on the distribution we will assume for $\mathbf{y}$, but is very similar to the last notation presented. A generic definition would be:

$$
\mathbf{y|u} \sim P(\mu, \; \phi)
$$

In which:

-   Linear predictor: $g(\mu) = \eta = \mathbf{X\beta + Zu}$

    -   $g(\mu) = \eta$ is the link function applied to the expected value

    -   $E(\mathbf{y|u}) = \mu$

$$
\\[0.2in]
$$

### Components of GLMMs

#### Link Functions

Our linear predictor $\mathbf{X\beta}$ can produce all possible values in the y-axis of a plot, from $- \; \infty$ to $+ \; \infty$ depending on the value of the predictor variable. A link function links the linear predictor and the distribution assumed for the data $\mathbf{y}$.

In the **link scale**, the mean of $\mathbf{y}$ respect linearity of the linear predictor. In the **response scale**, the mean $\mathbf{\mu}$ is back transformed by the inverse link and respects the support of the distribution.

The link function is applied to the expected value ($E(\mathbf{y})$), and not to the observations. Transformation of the observations also effect the error, while link functions only affect the parameters controlling the expected value.

Example of link functions:

| Link Function | Equation | Use | Why |
|:----------------:|:----------------:|:----------------:|:----------------:|
| **Identity Link** | $g(\mu) = \mu$ | Normal dist. | $E(\mathbf{y})$ can take any real value ($-\infty, \; +\infty$) |
| **Logit Link** | $g(\mathbf{\mu}) = log(\frac{\mu}{1-\mu})$ | Logistic, Beta, Binomial dist. | $E(\mathbf{y})$ can take any values between 0 and 1. Maps $(0, \; 1) \rightarrow (-\infty, \; +\infty)$ |
| **Log Link** | $g(\mu) = log(\mu)$ | Poisson, Gamma dist. | $E(\mathbf{y})$ can take any positive values ($\mu > 0$) |

$$
\\[0.2in]
$$

#### Distributional assumption for the data

GLMMs support different distributions from the exponential family. Distributions from the exponential family share common structure, but are relatively different among themselves.

-   **Assumption**: Something you take as true about your data or about the process that generated it!

Important distributions to know are:

-   **For continuous data**: Normal, t, Gamma, Beta.

-   **For discrete data**: Binomial, Poisson, Negative Binomial.

$$
\\[0.2in]
$$

<center>

#### **Normal distribution**

</center>

$$
y \sim N(\mu, \; \sigma^2)
$$

$$
E(y) = \mu \\
Var(y) = \sigma^2
$$

**Support:**

$$
y \in (-\infty, \; +\infty)
$$

```{r, echo=FALSE, warning=FALSE, message=FALSE}
x <- seq(-10, 10, 0.1) 
plot(x, dnorm(x, 0, 1), type = "l", lwd = 2, ylab = "[x]", xlab = "x", ylim = c(0, 0.4)) 
lines(x, dnorm(x, 0, 4), lty = 2) 
lines(x, dnorm(x, 2, 1), lty = 3) 
legend("topright", legend = c("x ~ Normal(0,1)", "x ~ Normal(0,16)", "x ~ Normal(2, 1)"), lty = c(1,2,3), bty = "n")
```

<center>

#### **Student t distribution**

</center>

$$
y\sim t_v(\mu, \; \sigma^2)
$$

<center>

$E(y) = \mu$ for $v > 1$, otherwise undefined

$Var(y) = \frac{v}{v-2} \sigma^2$, otherwise undefined

</center>

**Support:**

$$
y \in (-\infty, \; +\infty)
$$

```{r, echo=FALSE, warning=FALSE, message=FALSE}
x <- seq(-10, 10, 0.1) 
plot(x, dt(x, 2), type = "l", lwd = 2, ylab = "[x]", xlab = "x", ylim = c(0, 0.4)) 
lines(x, dt(x, 100), lty = 2) 
lines(x, dt(x, 2, 2), lty = 3) 
legend("topright", legend = c("x ~ t(2)", "x ~ t(100)", "x ~ t(2, 2)"), lty = c(1,2,3), bty = "n")
```

<center>

#### **Gamma distribution**

</center>

$$
y \sim Gamma(\alpha, \; \beta)
$$

$$
E(y) = \frac{\alpha}{\beta} \\
Var(y) = \frac{\alpha}{\beta^2}
$$

**Support:**

$$
y \in (0, \; +\infty)
$$

```{r, echo=FALSE, warning=FALSE, message=FALSE}
x <- seq(0, 12.5, 0.1) 
plot(x, dgamma(x, 2, 2), type = "l", lwd = 2, ylab = "[x]", xlab = "x", ylim = c(0, 1.5)) 
lines(x, dgamma(x, 10, 2), lty = 2) 
lines(x, dgamma(x, 3, 5), lty = 3) 
legend("topright", legend = c("x ~ Gamma(2, 2)", "x ~ Gamma(10, 2)", "x ~ Gamma(3, 5)"), lty = c(1,2,3), bty = "n")
```

<center>

#### **Beta distribution**

</center>

$$
y \sim Beta(\alpha, \; \beta)
$$

$$
E(y) = \frac{\alpha}{\alpha + \beta} \\
Var(y) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
$$

**Support**:

$$
y \in (0, \; 1)
$$

```{r, echo=FALSE, warning=FALSE, message=FALSE}
x <- seq(0.01, 0.99, 0.01) 
plot(x, dbeta(x, 0.5, 0.5), type = "l", lwd = 2, ylab = "[x]", xlab = "x", ylim = c(0, 3)) 
lines(x, dbeta(x, 1, 1), lty = 2) 
lines(x, dbeta(x, 4, 2), lty = 3) 
legend("top", legend = c("x ~ Beta(0.5, 0.5)", "x ~ Beta(1, 1)", "x ~ Beta(4, 2)"), lty = c(1,2,3), bty = "n")
```

<center>

#### **Poisson distribution**

</center>

$$
y \sim Poisson(\lambda)
$$

$$
E(y) = \lambda \\
Var(y) = \lambda
$$

**Support:**

$$
y \in (0, 1, 2, ..., +\infty)
$$

```{r, echo=FALSE, warning=FALSE, message=FALSE}
x <- seq(0, 17, 1)
off.set <- 0.2
plot(x, dpois(x, 2), type = "h", lwd = 6, ylab = "[x]", xlab = "x", ylim = c(0, 0.3), col = adjustcolor("#C3C3C3", alpha.f = 1)) 
lines(x + off.set, dpois(x, 6), type = "h", lwd = 6, col = adjustcolor("#757575", alpha.f = 1)) 
lines(x + 2*off.set, dpois(x, 10), type = "h", lwd = 6, col = adjustcolor("#1E1E1E", alpha.f = 1))  
legend("topright", legend = c("x ~ Pois(2)", "x ~ Pois(6)", "x ~ Pois(10)"), lty = c(1, 1, 1), lwd = 6, col = c("#C3C3C3", "#757575", "#1E1E1E"), bty = "n")
```

$$
\\[0.2 in]
$$

# Working with GLMMs

1.  Define a distribution that matches $y$
2.  Define the linear predictor (fixed and random effects) $\eta$
3.  Define the link function that connects $E(y)$ of the assume distribution and the linear predictor $\eta$

$$
\\[0.2 in]
$$

## Example I

In this example we will evaluate two different responses, yield and disease severity. The data was generated from a designed experiment on fungicide efficacy to manage the disease know and yellow rust on wheat. The experimental design was a Randomized Complete Block Design (RCBD).

### Yield

1.  Define a distribution that matches $y$

$$
y \sim N(\mu, \; \sigma^2)
$$

-   Why?

    -   Yields cannot be negative, but usually follow the normal bell-shaped pattern

2.  Define a linear predictor $\eta$

$$
\eta_{ij} = \mu_0 + t_i + u_j
$$

-   Where:

    -   $\mu_0$ represents the overall/gran mean

    <!-- -->

    -   $t_i$ is the parameter for the effect of treatment, in this case, fungicides - **Fixed effect**

    -   $u_j$ is the parameter for the effect of block - **Random effect**

3.  Define the link function that connects $E(y)$ of the assume distribution and the linear predictor $\eta$

<center>**Identity link**</center>

$$
g(\mu) = \eta = \mu
$$

-   Why?

    -   The linear predictor can produce values in the y-axis that range from $-\infty$ to $+\infty$, which matches the support of the assumed normal distribution, not requiring adjustments

    -   Remember the support of the normal distribution:

$$
y \in (-\infty, \; +\infty)
$$

#### **Analysis of yield**

**Data**

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(readxl)
library(ggplot2)
library(emmeans)
df <- read_excel("USA041.xlsx")
df$trt <- as.factor(df$trt)
df$rep <- as.factor(df$rep)

d1 <- df[,c(1, 2, 34)]
colnames(d1) <- c("fungicide", "block", "yield")
```

```{r, warning=FALSE, message=FALSE}
print(d1)
```

**Fitting the model**

```{r, warning=FALSE, message=FALSE}
library(glmmTMB)
m1 <- glmmTMB(yield ~ fungicide + (1|block), data = d1)
summary(m1)
```

**Checking the model - Residuals**

```{r, warning=FALSE, message=FALSE}
res <- residuals(m1, type = "pearson")
fit_link <- predict(m1, type = "link")

## QQ Plot
qqnorm(res)

## Heterogeneity
plot(fit_link, res, ylab = "Residuals", xlab = "Predicted")
```

**What are we checking here?**

...

**ANOVA**

```{r, warning=FALSE, message=FALSE}
library(car)
Anova(m1)
```

**Post-hoc test - Mean comparisons**

```{r, warning=FALSE, message=FALSE}
library(emmeans)
library(multcomp)
means <- emmeans(m1, ~ fungicide)
cld(means, Letters = letters)
```

$$
\\[0.2 in]
$$

### Severity

Severity refers to how much an specific plant organ is affected by a given disease. In this case it refers to the leaf area covered by yellow rust lesions, also know as pustules.

1.  Define a distribution that matches $y$

$$ y \sim Beta(\mu, \; \phi) $$

-   Why?

    -   Severity is a percentage: 0 - 100%, in proportion: 0 - 1

    -   The support from the Beta distribution perfectly matches our response

    -   Remember the support for the Beta distribution:

$$
y \in (0, \; 1)
$$

2.  Define a linear predictor $\eta$

$$ \eta_{ij} = \mu_0 + t_i + u_j $$

-   Where:

    -   $\mu_0$ represents the overall/gran mean

    <!-- -->

    -   $t_i$ is the parameter for the effect of treatment, in this case, fungicides - **Fixed effect**

    -   $u_j$ is the parameter for the effect of block - **Random effect**

3.  Define the link function that connects $E(y)$ of the assume distribution and the linear predictor $\eta$

<center>**Logit link**</center>

$$ g(\mu) = \eta = logit(\mu)$$

-   Why?

    -   Logit links $(-\infty, \; +\infty)$ to $(0, \; 1)$, that is our desired scale

#### **Analysis of severity**

**Data**

```{r, echo=FALSE, warning=FALSE, message=FALSE}
d2 <- df[,c(1, 2, 18)]
colnames(d2) <- c("fungicide", "block", "severity")
d2$severity <- d2$severity/100
```

```{r, warning=FALSE, message=FALSE}
print(d2)
```

**Fitting the model**

```{r, warning=FALSE, message=FALSE}
m2 <- glmmTMB(severity ~ fungicide + (1|block), family = beta_family(link = "logit"), data = d2)
summary(m2)
```

**Checking the model - Residuals**

Let's try the **pearson residuals** as we did for yield with the Normal/Gaussian distribution

```{r, warning=FALSE, message=FALSE}
res <- residuals(m2, type = "pearson")
fit_link <- predict(m2, type = "link")

## QQ Plot
qqnorm(res)

## Heterogeneity
plot(fit_link, res, ylab = "Residuals", xlab = "Predicted")
```

How about **simulated residuals**?

```{r, warning=FALSE, message=FALSE}
library(DHARMa)
simulateResiduals(m2, plot = TRUE)
```

**What are we checking here?**

...

**ANOVA**

```{r, warning=FALSE, message=FALSE}
Anova(m2)
```

**Post-hoc test - Mean comparisons**

```{r, warning=FALSE, message=FALSE}
means <- emmeans(m2, ~fungicide, type = "response")
cld(means, Letters = letters)
```
